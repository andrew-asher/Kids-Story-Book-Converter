{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the AllenAI MultiNews Dense Oracle dataset\n",
    "dataset = load_dataset(\"allenai/multinews_dense_oracle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a portion of the dataset for training (90% of the data)\n",
    "n_samples = int(len(dataset['train']) * 0.9)\n",
    "data = {'text': dataset['train']['document'][:n_samples], 'summary': dataset['train']['summary'][:n_samples]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base', use_fast=False)\n",
    "\n",
    "# Tokenize and preprocess the dataset\n",
    "tokenized_inputs = tokenizer(list(data['text']), max_length=512, truncation=True, padding='max_length', return_tensors='tf')\n",
    "tokenized_outputs = tokenizer(list(data['summary']), max_length=512, truncation=True, padding='max_length', return_tensors='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the T5 model architecture\n",
    "model = TFT5ForConditionalGeneration.from_pretrained('t5-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and accuracy metric\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_pred = tf.reshape(y_pred, (tf.shape(y_pred)[0], tf.shape(y_pred)[1], tf.shape(y_pred)[2]))\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.cast(y_true, tf.int32), tf.argmax(y_pred, axis=-1, output_type=tf.int32)), dtype=tf.float32))\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the inputs for training\n",
    "inputs = {\n",
    "    'input_ids': tokenized_inputs['input_ids'],\n",
    "    'attention_mask': tokenized_inputs['attention_mask'],\n",
    "    'labels': tokenized_outputs['input_ids'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad token is 0 for T5 models\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Shift the decoder inputs to the right, and prepend with pad tokens\n",
    "inputs['decoder_input_ids'] = tf.pad(inputs['labels'][:, :-1], [[0, 0], [1, 0]], constant_values=pad_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(inputs, tokenized_outputs['input_ids'], batch_size=16, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save_pretrained('/Users/andrewasher/Education/Research Project/Andrew/finetuned model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
